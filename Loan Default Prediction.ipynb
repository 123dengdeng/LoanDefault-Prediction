{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Prediction\n",
    "## Team Members:\n",
    "* Harish Puvvada\n",
    "* Vamsi Mohan Ramineedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,metrics \n",
    "from IPython.core.display import HTML\n",
    "pd.set_option(\"display.max_columns\",75)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model,svm\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2012_13 = pd.read_csv(os.getenv('FDS')+'LoanStats_2012_to_2013.csv',low_memory=False,skiprows=1)\n",
    "df2014 = pd.read_csv(os.getenv('FDS')+'LoanStats_2014.csv',low_memory=False,skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([df2012_13, df2014]) #merging 2007 to 2014 datasets\n",
    "dataset = dataset.iloc[:,2:111]          #removing empty columns\n",
    "empty_cols = [i for i in range(45,72)]   #more empty columns\n",
    "dataset = dataset.drop(dataset.columns[empty_cols],axis=1)\n",
    "data_with_loanstatus_sliced = dataset[(dataset['loan_status']==\"Fully Paid\") | (dataset['loan_status']==\"Charged Off\")]\n",
    "di = {\"Fully Paid\":0, \"Charged Off\":1}   #converting target variable to boolean\n",
    "Dataset_withBoolTarget= data_with_loanstatus_sliced.replace({\"loan_status\": di})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376233, 82)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_withBoolTarget['loan_status'].value_counts()\n",
    "Dataset_withBoolTarget.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376233, 74)\n"
     ]
    }
   ],
   "source": [
    "#print(Dataset_withBoolTarget.shape)\n",
    "dataset=Dataset_withBoolTarget.dropna(thresh = 340000,axis=1) #340000 is minimum number of non-NA values\n",
    "#print(x.isnull().sum()) #- to check how many null values in all the columns\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376233, 52)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_col_names = [\"delinq_2yrs\",  \"last_pymnt_d\", \"chargeoff_within_12_mths\",\"delinq_amnt\",\"emp_title\", \"term\", \"emp_title\", \"pymnt_plan\",\"purpose\",\"title\", \"zip_code\", \"verification_status\", \"dti\",\"earliest_cr_line\", \"initial_list_status\", \"out_prncp\",\n",
    "\"pymnt_plan\", \"num_tl_90g_dpd_24m\", \"num_tl_30dpd\", \"num_tl_120dpd_2m\", \"num_accts_ever_120_pd\", \"delinq_amnt\", \n",
    "\"chargeoff_within_12_mths\", \"total_rec_late_fee\", \"out_prncp_inv\", \"issue_d\"] #deleting some more columns\n",
    "dataset = dataset.drop(labels = del_col_names, axis = 1) \n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376233, 18)\n"
     ]
    }
   ],
   "source": [
    "features = ['funded_amnt','emp_length','annual_inc','home_ownership','grade',\n",
    "            \"last_pymnt_amnt\", \"mort_acc\", \"pub_rec\", \"int_rate\", \"open_acc\",\"num_actv_rev_tl\",\n",
    "            \"mo_sin_rcnt_rev_tl_op\",\"mo_sin_old_rev_tl_op\",\"bc_util\",\"bc_open_to_buy\",\n",
    "            \"avg_cur_bal\",\"acc_open_past_24mths\",'loan_status'] #selecting final features #'addr_state''tax_liens',\n",
    "Final_data = dataset[features] #19 features with target var\n",
    "Final_data[\"int_rate\"] = Final_data[\"int_rate\"].apply(lambda x:float(x[:-1]) ) #reomving % sign, conv to float  - int_rate column\n",
    "Final_data= Final_data.reset_index(drop=True)\n",
    "print(Final_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376233, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data encoding\n",
    "Final_data['grade'] = Final_data['grade'].map({'A':7,'B':6,'C':5,'D':4,'E':3,'F':2,'G':1})\n",
    "Final_data[\"home_ownership\"] = Final_data[\"home_ownership\"].map({\"MORTGAGE\":6,\"RENT\":5,\"OWN\":4,\"OTHER\":3,\"NONE\":2,\"ANY\":1})\n",
    "Final_data[\"emp_length\"] = Final_data[\"emp_length\"].replace({'years':'','year':'',' ':'','<':'','\\+':'','n/a':'0'}, regex = True)\n",
    "Final_data[\"emp_length\"] = Final_data[\"emp_length\"].apply(lambda x:int(x))\n",
    "Final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Missing values and Feature scaling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-65a3b52b37c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_clean' is not defined"
     ]
    }
   ],
   "source": [
    "data_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data.fillna(Final_data.mean(),inplace = True)\n",
    "HTML(Final_data.tail().to_html())\n",
    "Final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scl = preprocessing.StandardScaler() #instance of preprocessing\n",
    "fields = Final_data.columns.values[:-1] \n",
    "data_clean = pd.DataFrame(scl.fit_transform(Final_data[fields]), columns = fields)\n",
    "data_clean['loan_status'] = Final_data['loan_status']\n",
    "data_clean['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanstatus_0 = data_clean[data_clean[\"loan_status\"]==0]\n",
    "loanstatus_1 = data_clean[data_clean[\"loan_status\"]==1]\n",
    "subset_of_loanstatus_0 = loanstatus_0.sample(n=70000)\n",
    "data_clean = pd.concat([loanstatus_1, subset_of_loanstatus_0])\n",
    "data_clean = data_clean.sample(frac=1).reset_index(drop=True)\n",
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataViz = data_clean[['funded_amnt','emp_length','annual_inc','home_ownership','grade','last_pymnt_amnt','mort_acc','int_rate','open_acc','loan_status']]\n",
    "\n",
    "sns.set_context(context='notebook')\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "corr = dataViz.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.tril_indices_from(mask)] = True\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, cmap=cmap,linewidths=1, vmin=-1, vmax=1, square=True, cbar=True, center=0, ax=ax, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_clean.iloc[:,:-1], data_clean.iloc[:,-1], test_size=0.33, random_state=42)\n",
    "randomForest = RandomForestClassifier(criterion = \"gini\")\n",
    "randomForest.fit(X_train,y_train)\n",
    "rfPredict = randomForest.predict(X_test)\n",
    "rfAccuracy = accuracy_score(y_test,rfPredict)\n",
    "roc_score = metrics.roc_auc_score(y_test,rfPredict)\n",
    "print(rfAccuracy,roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "width=0.35\n",
    "ax.bar(np.arange(len(fields)), randomForest.feature_importances_, width, color='r')\n",
    "ax.set_xticks(np.arange(len(randomForest.feature_importances_)))\n",
    "ax.set_xticklabels(X_train.columns.values,rotation=90)\n",
    "plt.title('Feature Importance from DT')\n",
    "ax.set_ylabel('Normalized Gini Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set('talk', 'whitegrid', 'dark', font_scale=1, font='Ricty',rc={\"lines.linewidth\": 2, 'grid.linestyle': '--'})\n",
    "def plotAUC(truth, pred, lab):\n",
    "    fpr, tpr, _ = metrics.roc_curve(truth,pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, color='darkorange',lw=lw, label= lab +'(AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve') #Receiver Operating Characteristic \n",
    "    plt.legend(loc=\"lower right\")\n",
    "plotAUC(y_test,rfPredict, 'Random Forest')\n",
    "plt.show()\n",
    "\n",
    "average_precision = average_precision_score(y_test, rfPredict)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, rfPredict)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.step(recall, precision, color='b', alpha=0.2,where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LR = linear_model.LogisticRegression(C=1e30)\n",
    "clf_LR.fit(X_train,y_train)\n",
    "LR_Predict = clf_LR.predict_proba(X_test)[:,1]\n",
    "LR_Accuracy = accuracy_score(y_test,LR_Predict.round())\n",
    "print(LR_Accuracy)\n",
    "plotAUC(y_test,LR_Predict,'Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "average_precision = average_precision_score(y_test, LR_Predict)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, LR_Predict)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.step(recall, precision, color='b', alpha=0.2,where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines(SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_svm = svm.SVC(kernel = \"linear\")\n",
    "# clf_svm.fit(X_train,y_train)\n",
    "# predictions_svm = clf_svm.predict(X_test)\n",
    "# SVM_Accuracy = accuracy_score(y_test,predictions_svm)\n",
    "# print(SVM_Accuracy)\n",
    "# plotAUC(y_test,predictions_svm, 'SVM')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to be done before Initial Presentation\n",
    "\n",
    "2. Get proper reasoning to fill the NULL values.\n",
    "3. Get proper reasoning for scaling method that has to be applied.\n",
    "4. Few data visualizations(loan defaulters according to state, correlation plots etc.)\n",
    "5. Pick different combinations of features.\n",
    "7. Check for answers to potential questions.\n",
    "8. Have to go through \"how the company works\"\n",
    "9. Calculate precision and recall for the applied algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## extra features - acc_now_delinq, pct_tl_nvr_dlq, num_sats, sub_grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
